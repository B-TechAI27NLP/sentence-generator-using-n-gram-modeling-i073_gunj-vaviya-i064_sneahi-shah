{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-beJdDV7Gzre"
      },
      "outputs": [],
      "source": [
        "## SNEAHI SHAH\n",
        "## I064\n",
        "## NLP-LAB4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.util import ngrams"
      ],
      "metadata": {
        "id": "_3C9SuXFHvYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_4q-vshIh4a",
        "outputId": "af02c46f-087f-4d0b-85c6-e86c7a99637a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hamlet_tokens = [word.lower() for word in gutenberg.words('shakespeare-hamlet.txt')]"
      ],
      "metadata": {
        "id": "QVrjwB25Ihxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK 1\n",
        "# UNIGRAMS:\n",
        "hamlet_unigrams = list(ngrams(hamlet_tokens, 1))\n",
        "print(\"First 10 unigrams of Hamlet:\")\n",
        "print(hamlet_unigrams[:10])\n",
        "\n",
        "# BIGRAMS:\n",
        "hamlet_bigrams = list(ngrams(hamlet_tokens, 2))\n",
        "print(\"\\nFirst 10 bigrams of Hamlet:\")\n",
        "print(hamlet_bigrams[:10])\n",
        "\n",
        "# TRIGRAMS:\n",
        "hamlet_trigrams = list(ngrams(hamlet_tokens, 3))\n",
        "print(\"\\nFirst 10 trigrams of Hamlet:\")\n",
        "print(hamlet_trigrams[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxDn8XeGHvQ-",
        "outputId": "56745020-61d1-48f0-cfa9-d34b524537b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 unigrams of Hamlet:\n",
            "[('[',), ('the',), ('tragedie',), ('of',), ('hamlet',), ('by',), ('william',), ('shakespeare',), ('1599',), (']',)]\n",
            "\n",
            "First 10 bigrams of Hamlet:\n",
            "[('[', 'the'), ('the', 'tragedie'), ('tragedie', 'of'), ('of', 'hamlet'), ('hamlet', 'by'), ('by', 'william'), ('william', 'shakespeare'), ('shakespeare', '1599'), ('1599', ']'), (']', 'actus')]\n",
            "\n",
            "First 10 trigrams of Hamlet:\n",
            "[('[', 'the', 'tragedie'), ('the', 'tragedie', 'of'), ('tragedie', 'of', 'hamlet'), ('of', 'hamlet', 'by'), ('hamlet', 'by', 'william'), ('by', 'william', 'shakespeare'), ('william', 'shakespeare', '1599'), ('shakespeare', '1599', ']'), ('1599', ']', 'actus'), (']', 'actus', 'primus')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK 3\n",
        "from collections import Counter # Import Counter\n",
        "\n",
        "def build_model(ngrams_list):\n",
        "  model = {}\n",
        "  for gram in ngrams_list:\n",
        "    context = gram[:-1]\n",
        "    next_word = gram[-1]\n",
        "    if context not in model:\n",
        "      model[context] = Counter()\n",
        "    # Increment the count for the next word in the given context\n",
        "    model[context][next_word] += 1\n",
        "  return model"
      ],
      "metadata": {
        "id": "MTxPxa9WHvOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, context_tuple):\n",
        "    if context_tuple in model:\n",
        "        # Return the most common word in the Counter for this context\n",
        "        return model[context_tuple].most_common(1)[0][0]\n",
        "    else:\n",
        "        return \"No prediction available for this context.\""
      ],
      "metadata": {
        "id": "4lgX5vxjHvLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the bigram model\n",
        "bigram_model = build_model(hamlet_bigrams)"
      ],
      "metadata": {
        "id": "NNDnUSNdNJQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrate bigram prediction\n",
        "print(\"\\n--- Bigram Model Prediction ---\")\n",
        "bigram_context = ('of',)\n",
        "predicted_word_bigram = predict_next_word(bigram_model, bigram_context)\n",
        "print(f\"Context: {bigram_context}\")\n",
        "print(f\"Predicted next word: '{predicted_word_bigram}'\")\n",
        "print(f\"(Based on the most common word following '{bigram_context[0]}')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amBRCM6lNJOK",
        "outputId": "146c3841-2c73-40ff-d2d7-358e33cfe11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bigram Model Prediction ---\n",
            "Context: ('of',)\n",
            "Predicted next word: 'the'\n",
            "(Based on the most common word following 'of')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK 2\n",
        "import nltk\n",
        "from nltk import bigrams\n",
        "from nltk.probability import ConditionalFreqDist, ConditionalProbDist, MLEProbDist"
      ],
      "metadata": {
        "id": "aSXjRGThNJLi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training sentences\n",
        "sentences = [\n",
        "    \"This is a dog\",\n",
        "    \"This is a cat\",\n",
        "    \"I love my cat\",\n",
        "    \"This is my name\"\n",
        "]"
      ],
      "metadata": {
        "id": "6syIhLGsNJI7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"This is my cat\""
      ],
      "metadata": {
        "id": "Cl6grKlDshao"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdGdj6UgshYK",
        "outputId": "d403cd12-adcd-4a7d-85ba-c1373948613c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "    return [\"<s>\"] + tokens + [\"</s>\"]"
      ],
      "metadata": {
        "id": "1jsXQUGJshVI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize training sentences and generate bigrams\n",
        "train_tokens = [preprocess(sent) for sent in sentences]\n",
        "\n",
        "# Flatten the list of tokens for unigram counts\n",
        "all_words = [word for sent in train_tokens for word in sent]\n",
        "\n",
        "# Create Conditional Frequency Distribution for bigrams\n",
        "cfd = ConditionalFreqDist()\n",
        "\n",
        "for sent in train_tokens:\n",
        "    for w1, w2 in bigrams(sent):\n",
        "        cfd[w1][w2] += 1"
      ],
      "metadata": {
        "id": "OZtAJeCoshR5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Conditional Probability Distribution using MLE\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
        "\n",
        "# Preprocess the test sentence\n",
        "test_tokens = preprocess(test_sentence)"
      ],
      "metadata": {
        "id": "h9AlqPY2shMh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bigram probability of the test sentence\n",
        "prob = 1.0\n",
        "for w1, w2 in bigrams(test_tokens):\n",
        "    if w1 in cpd:\n",
        "        prob_w2_given_w1 = cpd[w1].prob(w2)\n",
        "        # If bigram probability is zero (not seen), overall prob is zero\n",
        "        if prob_w2_given_w1 == 0:\n",
        "            prob = 0\n",
        "            break\n",
        "        prob *= prob_w2_given_w1\n",
        "    else:\n",
        "        prob = 0\n",
        "        break\n",
        "\n",
        "print(f\"Probability of the sentence '{test_sentence}' is: {prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvA0D1oatZ02",
        "outputId": "b518d8ea-4f21-411e-b545-2d4a043f8347"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of the sentence 'This is my cat' is: 0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TASK 4\n",
        "def preprocess(sentence):\n",
        "    tokens = nltk.word_tokenize(sentence.lower())\n",
        "    return [\"<s>\"] + tokens + [\"</s>\"]"
      ],
      "metadata": {
        "id": "Uxn95dCwtZyV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from nltk.util import bigrams\n",
        "\n",
        "def calculate_perplexity(sentence, cpd_model):\n",
        "    \"\"\"\n",
        "    Calculates the perplexity of a sentence given a bigram probability model.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The input sentence.\n",
        "        cpd_model (ConditionalProbDist): The bigram probability model (ConditionalProbDist).\n",
        "\n",
        "    Returns:\n",
        "        float: The perplexity of the sentence.\n",
        "    \"\"\"\n",
        "    # Preprocess the sentence (add <s> and </s>)\n",
        "    tokens = preprocess(sentence)\n",
        "    n = len(tokens) - 1 # Number of bigrams\n",
        "\n",
        "    # Calculate the probability of the sentence using the bigram model\n",
        "    sentence_prob = 1.0\n",
        "    for w1, w2 in bigrams(tokens):\n",
        "        if w1 in cpd_model and cpd_model[w1].prob(w2) > 0:\n",
        "            sentence_prob *= cpd_model[w1].prob(w2)\n",
        "        else:\n",
        "            # Handle unseen bigrams (assign a very small probability or use smoothing)\n",
        "            # For simplicity here, we'll assign a small probability\n",
        "            sentence_prob *= 1e-10 # Assign a small probability for unseen bigrams\n",
        "\n",
        "    # Calculate perplexity\n",
        "    if sentence_prob == 0:\n",
        "        return float('inf')  # Perplexity is infinite if probability is zero\n",
        "    perplexity = (1/sentence_prob)**(1/n)\n",
        "    return perplexity"
      ],
      "metadata": {
        "id": "wxQO7yFytZv1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the perplexity of the test sentence\n",
        "perplexity_score = calculate_perplexity(test_sentence, cpd)\n",
        "print(f\"Perplexity of the sentence is: {perplexity_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GynFKqM_tZtO",
        "outputId": "15591549-ba3c-4724-ee2c-37c26be78f09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity of the sentence is: 1.5157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "The import nltk toolkit provides pre-built functions for tasks like tokenizing sentences into words. From nltk.util import ngrams selects a powerful tool for grouping words into sequences. From collections import Counter provides an efficient tool for counting word or word pair appearances in training data."
      ],
      "metadata": {
        "id": "6_Gpa-Drtzdo"
      }
    }
  ]
}